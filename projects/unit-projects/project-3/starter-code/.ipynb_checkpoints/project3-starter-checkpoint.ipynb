{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "In this project, you will perform a logistic regression on the admissions data we've been working with in projects 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n",
      "admit         int64\n",
      "gre         float64\n",
      "gpa         float64\n",
      "prestige    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"../assets/admissions.csv\")\n",
    "df = df_raw.dropna()        # drop NaN data\n",
    "print df.head()\n",
    "print df.dtypes              # 397 rows, observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Frequency Tables\n",
    "\n",
    "#### 1. Let's create a frequency table of our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xaa0e908>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEVCAYAAAACW4lMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa9c9748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frequency table for prestige and whether or not someone was admitted\n",
    "# tab1 = df.pivot_table(index=\"prestige\", values=\"admit\", aggfunc=np.sum)\n",
    "# tab1\n",
    "\n",
    "# create a 2ndary variable for Not_admit\n",
    "\n",
    "freq_data = pd.get_dummies(df, columns=[\"admit\"], prefix=\"admit\") # rows with two columns 0(not admit), 1(admit) added\n",
    "# freq_data\n",
    "\n",
    "tab1 = freq_data.pivot_table(index=\"prestige\", aggfunc=np.sum)    # pivot table, indexed by prestige, sum admittance\n",
    "tab1\n",
    "\n",
    "tab1[['admit_0', 'admit_1']].plot(kind='bar')\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Return of dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create class or dummy variables for prestige "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>700.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>520.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>780.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1</td>\n",
       "      <td>680.0</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1</td>\n",
       "      <td>680.0</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>1</td>\n",
       "      <td>480.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1</td>\n",
       "      <td>740.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>460.0</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  prestige_1.0  prestige_2.0  prestige_3.0  \\\n",
       "0        0  380.0  3.61           0.0           0.0           1.0   \n",
       "1        1  660.0  3.67           0.0           0.0           1.0   \n",
       "2        1  800.0  4.00           1.0           0.0           0.0   \n",
       "3        1  640.0  3.19           0.0           0.0           0.0   \n",
       "4        0  520.0  2.93           0.0           0.0           0.0   \n",
       "5        1  760.0  3.00           0.0           1.0           0.0   \n",
       "6        1  560.0  2.98           1.0           0.0           0.0   \n",
       "7        0  400.0  3.08           0.0           1.0           0.0   \n",
       "8        1  540.0  3.39           0.0           0.0           1.0   \n",
       "9        0  700.0  3.92           0.0           1.0           0.0   \n",
       "10       0  800.0  4.00           0.0           0.0           0.0   \n",
       "11       0  440.0  3.22           1.0           0.0           0.0   \n",
       "12       1  760.0  4.00           1.0           0.0           0.0   \n",
       "13       0  700.0  3.08           0.0           1.0           0.0   \n",
       "14       1  700.0  4.00           1.0           0.0           0.0   \n",
       "15       0  480.0  3.44           0.0           0.0           1.0   \n",
       "16       0  780.0  3.87           0.0           0.0           0.0   \n",
       "17       0  360.0  2.56           0.0           0.0           1.0   \n",
       "18       0  800.0  3.75           0.0           1.0           0.0   \n",
       "19       1  540.0  3.81           1.0           0.0           0.0   \n",
       "20       0  500.0  3.17           0.0           0.0           1.0   \n",
       "21       1  660.0  3.63           0.0           1.0           0.0   \n",
       "22       0  600.0  2.82           0.0           0.0           0.0   \n",
       "23       0  680.0  3.19           0.0           0.0           0.0   \n",
       "24       1  760.0  3.35           0.0           1.0           0.0   \n",
       "25       1  800.0  3.66           1.0           0.0           0.0   \n",
       "26       1  620.0  3.61           1.0           0.0           0.0   \n",
       "27       1  520.0  3.74           0.0           0.0           0.0   \n",
       "28       1  780.0  3.22           0.0           1.0           0.0   \n",
       "29       0  520.0  3.29           1.0           0.0           0.0   \n",
       "..     ...    ...   ...           ...           ...           ...   \n",
       "370      1  540.0  3.77           0.0           1.0           0.0   \n",
       "371      1  680.0  3.76           0.0           0.0           1.0   \n",
       "372      1  680.0  2.42           1.0           0.0           0.0   \n",
       "373      1  620.0  3.37           1.0           0.0           0.0   \n",
       "374      0  560.0  3.78           0.0           1.0           0.0   \n",
       "375      0  560.0  3.49           0.0           0.0           0.0   \n",
       "376      0  620.0  3.63           0.0           1.0           0.0   \n",
       "377      1  800.0  4.00           0.0           1.0           0.0   \n",
       "378      0  640.0  3.12           0.0           0.0           1.0   \n",
       "379      0  540.0  2.70           0.0           1.0           0.0   \n",
       "380      0  700.0  3.65           0.0           1.0           0.0   \n",
       "381      1  540.0  3.49           0.0           1.0           0.0   \n",
       "382      0  540.0  3.51           0.0           1.0           0.0   \n",
       "383      0  660.0  4.00           1.0           0.0           0.0   \n",
       "384      1  480.0  2.62           0.0           1.0           0.0   \n",
       "385      0  420.0  3.02           1.0           0.0           0.0   \n",
       "386      1  740.0  3.86           0.0           1.0           0.0   \n",
       "387      0  580.0  3.36           0.0           1.0           0.0   \n",
       "388      0  640.0  3.17           0.0           1.0           0.0   \n",
       "389      0  640.0  3.51           0.0           1.0           0.0   \n",
       "390      1  800.0  3.05           0.0           1.0           0.0   \n",
       "391      1  660.0  3.88           0.0           1.0           0.0   \n",
       "392      1  600.0  3.38           0.0           0.0           1.0   \n",
       "393      1  620.0  3.75           0.0           1.0           0.0   \n",
       "394      1  460.0  3.99           0.0           0.0           1.0   \n",
       "395      0  620.0  4.00           0.0           1.0           0.0   \n",
       "396      0  560.0  3.04           0.0           0.0           1.0   \n",
       "397      0  460.0  2.63           0.0           1.0           0.0   \n",
       "398      0  700.0  3.65           0.0           1.0           0.0   \n",
       "399      0  600.0  3.89           0.0           0.0           1.0   \n",
       "\n",
       "     prestige_4.0  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             1.0  \n",
       "4             1.0  \n",
       "5             0.0  \n",
       "6             0.0  \n",
       "7             0.0  \n",
       "8             0.0  \n",
       "9             0.0  \n",
       "10            1.0  \n",
       "11            0.0  \n",
       "12            0.0  \n",
       "13            0.0  \n",
       "14            0.0  \n",
       "15            0.0  \n",
       "16            1.0  \n",
       "17            0.0  \n",
       "18            0.0  \n",
       "19            0.0  \n",
       "20            0.0  \n",
       "21            0.0  \n",
       "22            1.0  \n",
       "23            1.0  \n",
       "24            0.0  \n",
       "25            0.0  \n",
       "26            0.0  \n",
       "27            1.0  \n",
       "28            0.0  \n",
       "29            0.0  \n",
       "..            ...  \n",
       "370           0.0  \n",
       "371           0.0  \n",
       "372           0.0  \n",
       "373           0.0  \n",
       "374           0.0  \n",
       "375           1.0  \n",
       "376           0.0  \n",
       "377           0.0  \n",
       "378           0.0  \n",
       "379           0.0  \n",
       "380           0.0  \n",
       "381           0.0  \n",
       "382           0.0  \n",
       "383           0.0  \n",
       "384           0.0  \n",
       "385           0.0  \n",
       "386           0.0  \n",
       "387           0.0  \n",
       "388           0.0  \n",
       "389           0.0  \n",
       "390           0.0  \n",
       "391           0.0  \n",
       "392           0.0  \n",
       "393           0.0  \n",
       "394           0.0  \n",
       "395           0.0  \n",
       "396           0.0  \n",
       "397           0.0  \n",
       "398           0.0  \n",
       "399           0.0  \n",
       "\n",
       "[397 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df\n",
    "\n",
    "dummy_ranks = pd.get_dummies(df, prefix=\"prestige\", columns=[\"prestige\"])    # create dummy variables from the prestige column\n",
    "dummy_ranks   # defined for use below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 When modeling our class variables, how many do we need? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The number of class variables - 1. For prestige we need 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Hand calculating odds ratios\n",
    "\n",
    "Develop your intuition about expected outcomes by hand calculating odds ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige_1.0  prestige_2.0  prestige_3.0  prestige_4.0\n",
      "0      0  380.0  3.61           0.0           0.0           1.0           0.0\n",
      "1      1  660.0  3.67           0.0           0.0           1.0           0.0\n",
      "2      1  800.0  4.00           1.0           0.0           0.0           0.0\n",
      "3      1  640.0  3.19           0.0           0.0           0.0           1.0\n",
      "4      0  520.0  2.93           0.0           0.0           0.0           1.0\n"
     ]
    }
   ],
   "source": [
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "\n",
    "handCalc = df[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_1.0':])    # dummy_ranks. IX indexing   prestige1: onward\n",
    "print handCalc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>admit</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>243</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "admit           0   1\n",
       "prestige_1.0         \n",
       "0.0           243  93\n",
       "1.0            28  33"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crosstab prestige 1 admission \n",
    "# frequency table cutting prestige and whether or not someone was admitted\n",
    "pd.crosstab(handCalc[\"prestige_1.0\"], handCalc['admit'])\n",
    "\n",
    "#handCalc.pivot_table(index=\"admit\", aggfunc=np.sum)    #pivot table looking at admittance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Use the cross tab above to calculate the odds of being admitted to grad school if you attended a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17857142857\n"
     ]
    }
   ],
   "source": [
    "# assuming that the outcomes are \"admit if attended a #1 ranked college\" vs \"not admit if attended a #1 ranked college\"\n",
    "# the odds  =  Probability of a favorable outcome/ Probability of a non favorable outcome\n",
    "odds_pres1 = 33.0/28.0\n",
    "print odds_pres1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Now calculate the odds of admission if you did not attend a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.382716049383\n"
     ]
    }
   ],
   "source": [
    "# If attending prestige2,3 or 4 colleges\n",
    "odds_pres234 = (93.0)/(243.0)     # using floating point, not integers\n",
    "print odds_pres234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Calculate the odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.07949308756\n"
     ]
    }
   ],
   "source": [
    "OR= odds_pres1/odds_pres234\n",
    "print OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Write this finding in a sentenance: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The ratio of the odds of admittance of attending a rank1 (prestige_1) college vs not attending a rank1 college (prestige 2,3 and 4) is 3.08. Someone has nearly three times the odds to be admitted if they attended a rank1 college vs someone who did not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Print the cross tab for prestige_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>admit</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_4.0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>216</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>55</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "admit           0    1\n",
       "prestige_4.0          \n",
       "0.0           216  114\n",
       "1.0            55   12"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(handCalc[\"prestige_4.0\"], handCalc['admit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Calculate the OR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.413397129187\n"
     ]
    }
   ],
   "source": [
    "OR_pres4 = (12.0/55.0)/(114.0/216.0)\n",
    "print OR_pres4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Write this finding in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The ratio of the odd of addmittance for attending a prestige4 school vs not attending a prestige4 school is 0.413. Someone has 0.413 the odds of being admitted if they are from a prestige4 college vs someone who is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0\n",
      "0      0  380.0  3.61           0.0           1.0           0.0\n",
      "1      1  660.0  3.67           0.0           1.0           0.0\n",
      "2      1  800.0  4.00           0.0           0.0           0.0\n",
      "3      1  640.0  3.19           0.0           0.0           1.0\n",
      "4      0  520.0  2.93           0.0           0.0           1.0\n"
     ]
    }
   ],
   "source": [
    "# create a clean data frame for the regression     # blog using logistic reg on the same data http://blog.yhat.com/posts/logistic-regression-and-python.html\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = df[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_2.0':])   # keep columns prestige2 onward\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to add a constant term for our Logistic Regression. The statsmodels function we're going to be using requires that intercepts/constants are specified explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0  intercept\n",
       "0      0  380.0  3.61           0.0           1.0           0.0        1.0\n",
       "1      1  660.0  3.67           0.0           1.0           0.0        1.0\n",
       "2      1  800.0  4.00           0.0           0.0           0.0        1.0\n",
       "3      1  640.0  3.19           0.0           0.0           1.0        1.0\n",
       "4      0  520.0  2.93           0.0           0.0           1.0        1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually add the intercept           # code as in the yhatblog\n",
    "data['intercept'] = 1.0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Set the covariates to a variable called train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'gre', u'gpa', u'prestige_2.0', u'prestige_3.0', u'prestige_4.0',\n",
       "       u'intercept'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols=data.columns[1:]                         #training columns, or the predictors, covariates\n",
    "# train_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573854\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "#sm.Logit(y, X).fit().summary()    # from a stack exchange post. # imported: statsmodels.api as sm\n",
    "\n",
    "model = sm.Logit(data[\"admit\"],data[train_cols]).fit()          # outcome, predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Print the summary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>admit</td>      <th>  No. Observations:  </th>  <td>   397</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   391</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 10 Oct 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.08166</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:17:59</td>     <th>  Log-Likelihood:    </th> <td> -227.82</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -248.08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.176e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>          <td>    0.0022</td> <td>    0.001</td> <td>    2.028</td> <td> 0.043</td> <td> 7.44e-05     0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>          <td>    0.7793</td> <td>    0.333</td> <td>    2.344</td> <td> 0.019</td> <td>    0.128     1.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_2.0</th> <td>   -0.6801</td> <td>    0.317</td> <td>   -2.146</td> <td> 0.032</td> <td>   -1.301    -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_3.0</th> <td>   -1.3387</td> <td>    0.345</td> <td>   -3.882</td> <td> 0.000</td> <td>   -2.015    -0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_4.0</th> <td>   -1.5534</td> <td>    0.417</td> <td>   -3.721</td> <td> 0.000</td> <td>   -2.372    -0.735</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>    <td>   -3.8769</td> <td>    1.142</td> <td>   -3.393</td> <td> 0.001</td> <td>   -6.116    -1.638</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  397\n",
       "Model:                          Logit   Df Residuals:                      391\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Mon, 10 Oct 2016   Pseudo R-squ.:                 0.08166\n",
       "Time:                        13:17:59   Log-Likelihood:                -227.82\n",
       "converged:                       True   LL-Null:                       -248.08\n",
       "                                        LLR p-value:                 1.176e-07\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------\n",
       "gre              0.0022      0.001      2.028      0.043      7.44e-05     0.004\n",
       "gpa              0.7793      0.333      2.344      0.019         0.128     1.431\n",
       "prestige_2.0    -0.6801      0.317     -2.146      0.032        -1.301    -0.059\n",
       "prestige_3.0    -1.3387      0.345     -3.882      0.000        -2.015    -0.663\n",
       "prestige_4.0    -1.5534      0.417     -3.721      0.000        -2.372    -0.735\n",
       "intercept       -3.8769      1.142     -3.393      0.001        -6.116    -1.638\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()           # taking the exp() of the coef gives Odds Ratio.   logistic regression uses the sigmoid funct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Calculate the odds ratios of the coeffiencents and their 95% CI intervals\n",
    "\n",
    "hint 1: np.exp(X)\n",
    "\n",
    "hint 2: conf['OR'] = params\n",
    "        \n",
    "           conf.columns = ['2.5%', '97.5%', 'OR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds Ratios\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gre             1.002221\n",
       "gpa             2.180027\n",
       "prestige_2.0    0.506548\n",
       "prestige_3.0    0.262192\n",
       "prestige_4.0    0.211525\n",
       "intercept       0.020716\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Odds Ratios\"\n",
    "np.exp(model.params)          # taking the exponential of the coefs gives the Odds Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Conf. Intervals\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gre</th>\n",
       "      <td>1.000074</td>\n",
       "      <td>1.004372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>1.136120</td>\n",
       "      <td>4.183113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_2.0</th>\n",
       "      <td>0.272168</td>\n",
       "      <td>0.942767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_3.0</th>\n",
       "      <td>0.133377</td>\n",
       "      <td>0.515419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_4.0</th>\n",
       "      <td>0.093329</td>\n",
       "      <td>0.479411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>0.002207</td>\n",
       "      <td>0.194440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  2.5%     97.5%\n",
       "gre           1.000074  1.004372\n",
       "gpa           1.136120  4.183113\n",
       "prestige_2.0  0.272168  0.942767\n",
       "prestige_3.0  0.133377  0.515419\n",
       "prestige_4.0  0.093329  0.479411\n",
       "intercept     0.002207  0.194440"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"95% Conf. Intervals\"\n",
    "CI = np.exp(model.conf_int())         # or model.conf_int().apply(np.exp)\n",
    "CI.columns = [\"2.5%\", \"97.5%\"]        # name the columns\n",
    "CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Interpret the OR of Prestige_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The odds of admittance become 0.5 for someone who attended a prestige2 college."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Interpret the OR of GPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The odds of admittance increase by 1.135 for every unit GPA increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Predicted probablities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way of evaluating our classifier, we're going to recreate the dataset with every logical combination of input values. This will allow us to see how the predicted probability of admission increases/decreases across different variables. First we're going to generate the combinations using a helper function called cartesian (above).\n",
    "\n",
    "We're going to use np.linspace to create a range of values for \"gre\" and \"gpa\". This creates a range of linearly spaced values from a specified min and maximum value--in our case just the min/max observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"\n",
    "    Generate a cartesian product of input arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "\n",
    "    m = n / arrays[0].size\n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m,1:])\n",
    "        for j in xrange(1, arrays[0].size):\n",
    "            out[j*m:(j+1)*m,1:] = out[0:m,1:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 220.          284.44444444  348.88888889  413.33333333  477.77777778\n",
      "  542.22222222  606.66666667  671.11111111  735.55555556  800.        ]\n",
      "[ 2.26        2.45333333  2.64666667  2.84        3.03333333  3.22666667\n",
      "  3.42        3.61333333  3.80666667  4.        ]\n"
     ]
    }
   ],
   "source": [
    "# instead of generating all possible values of GRE and GPA, we're going\n",
    "# to use an evenly spaced range of 10 values from the min to the max \n",
    "gres = np.linspace(data['gre'].min(), data['gre'].max(), 10)\n",
    "print gres\n",
    "# array([ 220.        ,  284.44444444,  348.88888889,  413.33333333,\n",
    "#         477.77777778,  542.22222222,  606.66666667,  671.11111111,\n",
    "#         735.55555556,  800.        ])\n",
    "gpas = np.linspace(data['gpa'].min(), data['gpa'].max(), 10)\n",
    "print gpas\n",
    "# array([ 2.26      ,  2.45333333,  2.64666667,  2.84      ,  3.03333333,\n",
    "#         3.22666667,  3.42      ,  3.61333333,  3.80666667,  4.        ])\n",
    "\n",
    "\n",
    "# enumerate all possibilities\n",
    "combos = pd.DataFrame(cartesian([gres, gpas, [1, 2, 3, 4], [1.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Recreate the dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre       gpa  prestige_2.0  prestige_3.0  prestige_4.0  intercept\n",
       "0  220.0  2.260000           0.0           0.0           0.0        1.0\n",
       "1  220.0  2.260000           1.0           0.0           0.0        1.0\n",
       "2  220.0  2.260000           0.0           1.0           0.0        1.0\n",
       "3  220.0  2.260000           0.0           0.0           1.0        1.0\n",
       "4  220.0  2.453333           0.0           0.0           0.0        1.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recreate the dummy variables\n",
    "\n",
    "combos.columns = ['gre','gpa','prestige','intercept']      # specify the names of the columns\n",
    "\n",
    "combos.head()   # col1 GRE, col2 GPA, col3 Prestige, col4 is the linear term\n",
    "\n",
    "combos_df=pd.get_dummies(combos, columns=[\"prestige\"],drop_first=True)   # get_dummies and drop first category\n",
    "\n",
    "# keep only what we need for making predictions\n",
    "combos_df.head()                                   # intercept is now ordered before prestige\n",
    "combos_df= combos_df.loc[:,[\"gre\",\"gpa\", \"prestige_2.0\",\"prestige_3.0\",\"prestige_4.0\",\"intercept\"]]   #re order, using index locating\n",
    "combos_df.head()                                   # can also use the dummy procedure as above, with .join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Make predictions on the enumerated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "      <th>intercept</th>\n",
       "      <th>admit_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.806667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.334286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.582995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.419833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.368608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gre       gpa  prestige_2.0  prestige_3.0  prestige_4.0  intercept  \\\n",
       "395  800.0  3.806667           0.0           0.0           1.0        1.0   \n",
       "396  800.0  4.000000           0.0           0.0           0.0        1.0   \n",
       "397  800.0  4.000000           1.0           0.0           0.0        1.0   \n",
       "398  800.0  4.000000           0.0           1.0           0.0        1.0   \n",
       "399  800.0  4.000000           0.0           0.0           1.0        1.0   \n",
       "\n",
       "     admit_predict  \n",
       "395       0.334286  \n",
       "396       0.734040  \n",
       "397       0.582995  \n",
       "398       0.419833  \n",
       "399       0.368608  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admit_predict = model.predict(combos_df[train_cols])      # may not need to reorder combos_df above, b/c using the train_cols index here\n",
    "admit_predict[-1:-1-5:-1]   # counts from the last, backwards 5 elements\n",
    "admit_predict[-1]    # for np arrays (and arrays,[1,2,3]) returns the last element (like matlab's end)\n",
    "\n",
    "#array1=np.array([1,2,3])\n",
    "#array1[-1]\n",
    "\n",
    "# add the predictions to the combos_df dataframe\n",
    "combos_df[\"admit_predict\"]=admit_predict\n",
    "\n",
    "combos_df.tail(5)        #look at the last 5 rows of the dataframe, with predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Interpret findings for the last 4 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The last four rows or observations all have a GRE of 800 and a GPA of 4. The predicted admit value is the highest for a student from a prestige1 college (row 396). The predicted admit value decreases as the college prestige goes from 2 to 4 (decreasing prestige)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Plot the probability of being admitted into graduate school, stratified by GPA and GRE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
